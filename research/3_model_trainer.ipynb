{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\STUDY\\TENSORFLOW\\Projects\\1_CNN_Project\\research\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\STUDY\\\\TENSORFLOW\\\\Projects\\\\1_CNN_Project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the src/cnn_classifier/entity\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir:Path\n",
    "    trained_model_path:Path\n",
    "    custom_base_model_path:Path\n",
    "    training_data:Path\n",
    "    testing_data:Path\n",
    "    params_epochs:int\n",
    "    params_batch_size:int\n",
    "    params_is_augmentation:bool\n",
    "    params_image_size:list | tuple\n",
    "    params_learning_rate:float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the src/cnn_classifier/config/configuration.\n",
    "\n",
    "from cnn_classifier.constants import *\n",
    "from cnn_classifier.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config=read_yaml(config_filepath)\n",
    "        self.params=read_yaml(params_filepath)\n",
    "\n",
    "        # Creating directory\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "\n",
    "        params=self.params\n",
    "        training=self.config.training\n",
    "        prepare_base_model=self.config.prepare_base_model\n",
    "        \n",
    "\n",
    "        training_data=Path(os.path.join(self.config.data_ingestion.unzip_dir, r\"data/train\") )\n",
    "        testing_data=Path(os.path.join(self.config.data_ingestion.unzip_dir, r\"data/test\") )\n",
    "\n",
    "        create_directories( [Path(training.root_dir)] )\n",
    "\n",
    "        training_config=TrainingConfig(\n",
    "\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            custom_base_model_path=Path(prepare_base_model.custom_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            testing_data=Path(testing_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.INPUT_SHAPE,\n",
    "            params_learning_rate=params.LEARNING_RATE\n",
    "        )\n",
    "\n",
    "        return training_config\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the src/cnn_classifier/components.\n",
    "import os\n",
    "from urllib import request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras.utils import image_dataset_from_directory as Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "\n",
    "    def __init__(self, config:TrainingConfig):\n",
    "        self.config=config\n",
    "\n",
    "    def get_custom_base_model(self):\n",
    "\n",
    "        self.model=tf.keras.models.load_model( \n",
    "                    self.config.custom_base_model_path\n",
    "                    )\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_model(path:Path, model:tf.keras.Model):\n",
    "\n",
    "        model.save(path)\n",
    "\n",
    "    def preprocess_data(self):\n",
    "\n",
    "        # Load images and split them into batches\n",
    "        self.images_train = Images(\n",
    "                            directory=self.config.training_data,\n",
    "                            labels='inferred',\n",
    "                            image_size = self.config.params_image_size[:-1],\n",
    "                            batch_size = self.config.params_batch_size\n",
    "                            )\n",
    "\n",
    "        self.images_test = Images(\n",
    "                            directory=self.config.testing_data,\n",
    "                            labels='inferred',\n",
    "                            image_size = self.config.params_image_size[:-1],\n",
    "                            batch_size = self.config.params_batch_size\n",
    "                            )\n",
    "        \n",
    "    def train(self):\n",
    "\n",
    "        if self.config.params_is_augmentation:\n",
    "\n",
    "            data_aug_layers = tf.keras.Sequential(\n",
    "                [\n",
    "                    tf.keras.layers.RandomFlip(mode='horizontal_and_vertical' ,\n",
    "                                               training=True, \n",
    "                                               name=\"Random_flip_layer\" ),\n",
    "                    tf.keras.layers.RandomTranslation(height_factor=(-0.1,.1),\n",
    "                                                    width_factor=(-0.1,0.1),\n",
    "                                                    fill_mode=\"reflect\", \n",
    "                                                    name= \"Random_translation_layers\"),\n",
    "                    tf.keras.layers.RandomRotation(factor=(-0.1,0.1), \n",
    "                                                   name=\"Random_rotation_layer\"),\n",
    "                    tf.keras.layers.RandomZoom(height_factor=(0.1,0.1),\n",
    "                                               width_factor=(0.1,0.1), \n",
    "                                               name=\"Random_zoom_layer\" )\n",
    "                ],\n",
    "                name=\"data_augmentation_layers\"\n",
    "                    )\n",
    "            \n",
    "            # Creating new model on top\n",
    "            inputs=tf.keras.Input(shape=self.config.params_image_size, name=\"input_layer\")\n",
    "\n",
    "            # Apply random data augmentation\n",
    "            x = data_aug_layers(inputs )\n",
    "\n",
    "            Outputs = self.model(x, training=False)\n",
    "\n",
    "            self.full_model = tf.keras.models.Model(\n",
    "                                  inputs=inputs,\n",
    "                                  outputs=Outputs\n",
    "                                  )\n",
    "\n",
    "        else :\n",
    "            self.full_model = self.model\n",
    "\n",
    "        # Compiling the model\n",
    "        self.full_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.config.params_learning_rate),\n",
    "                                loss=\"binary_crossentropy\",\n",
    "                                metrics=[\"accuracy\"])\n",
    "        \n",
    "        #Fit the model\n",
    "        self.history_fm = self.full_model.fit(x=self.images_train,\n",
    "                                              validation_data=self.images_test,\n",
    "                                              epochs=self.config.params_epochs)\n",
    "\n",
    "\n",
    "        self.save_model(\n",
    "                        path=self.config.trained_model_path,\n",
    "                        model=self.full_model\n",
    "                       )\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-25 11:10:25,720 : INFO : common : yaml file : config\\config.yaml loaded successfully]\n",
      "[2025-04-25 11:10:25,720 : INFO : common : yaml file : params.yaml loaded successfully]\n",
      "[2025-04-25 11:10:25,720 : INFO : common : Created directory at : artifacts]\n",
      "[2025-04-25 11:10:25,720 : INFO : common : Created directory at : trained_model\\training]\n",
      "Found 369 files belonging to 2 classes.\n",
      "Found 174 files belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 700ms/step - accuracy: 0.6197 - loss: 5.2932 - val_accuracy: 0.8908 - val_loss: 0.7866\n",
      "Epoch 2/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 761ms/step - accuracy: 0.9627 - loss: 0.4146 - val_accuracy: 0.9885 - val_loss: 0.1824\n",
      "Epoch 3/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 956ms/step - accuracy: 1.0000 - loss: 2.5017e-06 - val_accuracy: 0.9770 - val_loss: 0.2110\n",
      "Epoch 4/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.0353e-06 - val_accuracy: 0.9770 - val_loss: 0.2145\n",
      "Epoch 5/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.6265e-06 - val_accuracy: 0.9770 - val_loss: 0.2148\n"
     ]
    }
   ],
   "source": [
    "# Pipeline\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_custom_base_model()\n",
    "    training.preprocess_data()\n",
    "    training.train()\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
